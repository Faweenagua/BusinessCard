{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Faweenagua/BusinessCard/blob/master/Copy_of_Main_Course.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aQ9WUU0Fy3_B"
      },
      "outputs": [],
      "source": [
        "# https://stable-baselines3.readthedocs.io/en/master/guide/rl.html\n",
        "# https://spinningup.openai.com/en/latest/spinningup/rl_intro2.html#a-taxonomy-of-rl-algorithms"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z6N8NAqny3_C"
      },
      "source": [
        "# 1. Import dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YdX6fq3ky3_C"
      },
      "outputs": [],
      "source": [
        "!pip install stable-baselines3[extra]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7v9bJjujy3_D"
      },
      "outputs": [],
      "source": [
        "import gym\n",
        "from stable_baselines3 import PPO\n",
        "from stable_baselines3.common.vec_env import DummyVecEnv\n",
        "from stable_baselines3.common.evaluation import evaluate_policy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_aBs83Vay3_D"
      },
      "source": [
        "# 2. Load Environment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Odq1hbdXy3_D"
      },
      "outputs": [],
      "source": [
        "environment_name = \"CartPole-v0\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PLMva5Zjy3_D"
      },
      "outputs": [],
      "source": [
        "env = gym.make(environment_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Glxmj2Djy3_D"
      },
      "outputs": [],
      "source": [
        "episodes = 5\n",
        "for episode in range(1, episodes+1):\n",
        "    state = env.reset()\n",
        "    done = False\n",
        "    score = 0\n",
        "\n",
        "    while not done:\n",
        "        env.render()\n",
        "        action = env.action_space.sample()\n",
        "        n_state, reward, done, info = env.step(action)\n",
        "        score+=reward\n",
        "    print('Episode:{} Score:{}'.format(episode, score))\n",
        "env.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c4iYyq1Yy3_D"
      },
      "source": [
        "# Understanding The Environment\n",
        "https://github.com/openai/gym/blob/master/gym/envs/classic_control/cartpole.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NM3U-Tbiy3_E"
      },
      "outputs": [],
      "source": [
        "# 0-push cart to left, 1-push cart to the right\n",
        "env.action_space.sample()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HVcmDBaPy3_E"
      },
      "outputs": [],
      "source": [
        "# [cart position, cart velocity, pole angle, pole angular velocity]\n",
        "env.observation_space.sample()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KVLSqVt1y3_E"
      },
      "source": [
        "# 3. Train an RL Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "frVhfTkky3_E"
      },
      "outputs": [],
      "source": [
        "env = gym.make(environment_name)\n",
        "env = DummyVecEnv([lambda: env])\n",
        "model = PPO('MlpPolicy', env, verbose = 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "_Ug5mTuJy3_E"
      },
      "outputs": [],
      "source": [
        "model.learn(total_timesteps=20000)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t_kDTqvyy3_E"
      },
      "source": [
        "# 4. Save and Reload Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "skMxU9uty3_E"
      },
      "outputs": [],
      "source": [
        "PPO_path = os.path.join('Training', 'Saved Models', 'PPO_model')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5n4CEFisy3_E"
      },
      "outputs": [],
      "source": [
        "model.save(PPO_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tYLahWHOy3_E"
      },
      "outputs": [],
      "source": [
        "del model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wpUxJfihy3_F"
      },
      "outputs": [],
      "source": [
        "model = PPO.load('PPO_model', env=env)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tJiroPXFy3_F"
      },
      "source": [
        "# 4. Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gu98nrw2y3_F"
      },
      "outputs": [],
      "source": [
        "from stable_baselines3.common.evaluation import evaluate_policy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oG_FWh70y3_F"
      },
      "outputs": [],
      "source": [
        "evaluate_policy(model, env, n_eval_episodes=10, render=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GLLSXBmyy3_F"
      },
      "outputs": [],
      "source": [
        "env.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WVgl1vNEy3_F"
      },
      "source": [
        "# 5. Test Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jRMqCUI4y3_F"
      },
      "outputs": [],
      "source": [
        "obs = env.reset()\n",
        "while True:\n",
        "    action, _states = model.predict(obs)\n",
        "    obs, rewards, done, info = env.step(action)\n",
        "    env.render()\n",
        "    if done:\n",
        "        print('info', info)\n",
        "        break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8w4t3-w2y3_F"
      },
      "outputs": [],
      "source": [
        "env.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t3lLZ67Ty3_F"
      },
      "source": [
        "# 6. Viewing Logs in Tensorboard"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dKB0gTw9y3_F"
      },
      "outputs": [],
      "source": [
        "training_log_path = os.path.join(log_path, 'PPO_3')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "spOVtkdJy3_F"
      },
      "outputs": [],
      "source": [
        "!tensorboard --logdir={training_log_path}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "au0x-H8ey3_F"
      },
      "source": [
        "# 7. Adding a callback to the training Stage"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MzY0dIFay3_G"
      },
      "outputs": [],
      "source": [
        "from stable_baselines3.common.callbacks import EvalCallback, StopTrainingOnRewardThreshold\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "itcYYExAy3_G"
      },
      "outputs": [],
      "source": [
        "save_path = os.path.join('Training', 'Saved Models')\n",
        "log_path = os.path.join('Training', 'Logs')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oPSS_QP2y3_G"
      },
      "outputs": [],
      "source": [
        "env = gym.make(environment_name)\n",
        "env = DummyVecEnv([lambda: env])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i-rBQrqIy3_G"
      },
      "outputs": [],
      "source": [
        "stop_callback = StopTrainingOnRewardThreshold(reward_threshold=190, verbose=1)\n",
        "eval_callback = EvalCallback(env,\n",
        "                             callback_on_new_best=stop_callback,\n",
        "                             eval_freq=10000,\n",
        "                             best_model_save_path=save_path,\n",
        "                             verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DMj-jr-ey3_G"
      },
      "outputs": [],
      "source": [
        "model = PPO('MlpPolicy', env, verbose = 1, tensorboard_log=log_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "dwwy5_Nyy3_G"
      },
      "outputs": [],
      "source": [
        "model.learn(total_timesteps=20000, callback=eval_callback)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JgOtFuCgy3_G"
      },
      "outputs": [],
      "source": [
        "model_path = os.path.join('Training', 'Saved Models', 'best_model')\n",
        "model = PPO.load(model_path, env=env)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ejTb29mpy3_G"
      },
      "outputs": [],
      "source": [
        "evaluate_policy(model, env, n_eval_episodes=10, render=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o39-ht1Vy3_G"
      },
      "outputs": [],
      "source": [
        "env.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7_-sc25dy3_K"
      },
      "source": [
        "# 8. Changing Policies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DqnuxHwMy3_K"
      },
      "outputs": [],
      "source": [
        "net_arch=[dict(pi=[128, 128, 128, 128], vf=[128, 128, 128, 128])]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SP4TvbeRy3_K"
      },
      "outputs": [],
      "source": [
        "model = PPO('MlpPolicy', env, verbose = 1, policy_kwargs={'net_arch': net_arch})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "yv1WJQVky3_K"
      },
      "outputs": [],
      "source": [
        "model.learn(total_timesteps=20000, callback=eval_callback)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "am-pUMg2y3_K"
      },
      "source": [
        "# 9. Using an Alternate Algorithm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eUSrqMEiy3_K"
      },
      "outputs": [],
      "source": [
        "from stable_baselines3 import DQN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TMQWBT3Ny3_K"
      },
      "outputs": [],
      "source": [
        "model = DQN('MlpPolicy', env, verbose = 1, tensorboard_log=log_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "eosnOWpby3_L"
      },
      "outputs": [],
      "source": [
        "model.learn(total_timesteps=20000, callback=eval_callback)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LH0fynvty3_L"
      },
      "outputs": [],
      "source": [
        "dqn_path = os.path.join('Training', 'Saved Models', 'DQN_model')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yqx-sgKpy3_L"
      },
      "outputs": [],
      "source": [
        "model.save(dqn_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_id9KJaty3_L"
      },
      "outputs": [],
      "source": [
        "model = DQN.load(dqn_path, env=env)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "12Lfvyfky3_L"
      },
      "outputs": [],
      "source": [
        "evaluate_policy(model, env, n_eval_episodes=10, render=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F1jmDPuUy3_L"
      },
      "outputs": [],
      "source": [
        "env.close()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "rlcourse",
      "language": "python",
      "name": "rlcourse"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}